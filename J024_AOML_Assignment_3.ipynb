{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Feature Encoding Challenge II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to load train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv(\"data/cfec_train.csv\")\n",
    "    test = pd.read_csv(\"data/cfec_test.csv\")\n",
    "    target_col = \"target\" if \"target\" in train.columns else train.columns[-1]\n",
    "    return train, test, target_col\n",
    "\n",
    "\n",
    "train, test, target_col = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_cols = train.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "numerical_cols.remove(target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "train[categorical_cols] = imputer.fit_transform(train[categorical_cols])\n",
    "test[categorical_cols] = imputer.transform(test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=categorical_cols)\n",
    "train[categorical_cols] = encoder.fit_transform(\n",
    "    train[categorical_cols], train[target_col]\n",
    ")\n",
    "test[categorical_cols] = encoder.transform(test[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train[numerical_cols] = scaler.fit_transform(train[numerical_cols])\n",
    "test[numerical_cols] = scaler.transform(test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[target_col])\n",
    "y = train[target_col]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train and evaluate a model using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Model: {model.__class__.__name__} | Accuracy: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation using accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: RandomForestClassifier | Accuracy: 0.8218\n",
      "Model: XGBClassifier | Accuracy: 0.8255\n",
      "[LightGBM] [Info] Number of positive: 89858, number of negative: 390142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1789\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187204 -> initscore=-1.468280\n",
      "[LightGBM] [Info] Start training from score -1.468280\n",
      "Model: LGBMClassifier | Accuracy: 0.8272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8272"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(eval_metric=\"logloss\")\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "evaluate_model(rf, X_train, X_val, y_train, y_val)\n",
    "evaluate_model(xgb, X_train, X_val, y_train, y_val)\n",
    "evaluate_model(lgbm, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\itssp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:41:14] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"n_estimators\": [100, 200],\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    param_grid_xgb,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(f\"Best XGBoost params: {grid_xgb.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[LightGBM] [Info] Number of positive: 89858, number of negative: 390142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1789\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187204 -> initscore=-1.468280\n",
      "[LightGBM] [Info] Start training from score -1.468280\n",
      "Best LightGBM params: {'num_leaves': 20, 'n_estimators': 300, 'learning_rate': 0.05}\n"
     ]
    }
   ],
   "source": [
    "param_grid_lgbm = {\n",
    "    \"num_leaves\": [20, 31],\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"n_estimators\": [100, 300],\n",
    "}\n",
    "\n",
    "random_lgbm = RandomizedSearchCV(\n",
    "    LGBMClassifier(),\n",
    "    param_grid_lgbm,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "random_lgbm.fit(X_train, y_train)\n",
    "print(f\"Best LightGBM params: {random_lgbm.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final LightGBM Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 89858, number of negative: 390142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1789\n",
      "[LightGBM] [Info] Number of data points in the train set: 480000, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.187204 -> initscore=-1.468280\n",
      "[LightGBM] [Info] Start training from score -1.468280\n",
      "Final Model Accuracy: 0.8274\n"
     ]
    }
   ],
   "source": [
    "final_model = LGBMClassifier(**random_lgbm.best_params_)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_final_pred = final_model.predict(X_val)\n",
    "\n",
    "final_acc = accuracy_score(y_val, y_final_pred)\n",
    "print(f\"Final Model Accuracy: {final_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with a Tabular Gemstone Price Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemstone = pd.read_csv(\"data/gemstone.csv\")\n",
    "\n",
    "X = gemstone.drop(columns=[\"price\"])\n",
    "y = gemstone[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Values in Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X[categorical_cols] = imputer.fit_transform(X[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.TargetEncoder(cols=categorical_cols)\n",
    "X[categorical_cols] = encoder.fit_transform(X[categorical_cols], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Ordinal Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"cut\"] = X[\"cut\"].map({\"Very Good\": 4, \"Good\": 3, \"Fair\": 2, \"Poor\": 1})\n",
    "X[\"color\"] = X[\"color\"].map({\"D\": 7, \"E\": 6, \"F\": 5, \"G\": 4, \"H\": 3, \"I\": 2, \"J\": 1})\n",
    "X[\"clarity\"] = X[\"clarity\"].map(\n",
    "    {\"IF\": 8, \"VVS1\": 7, \"VVS2\": 6, \"VS1\": 5, \"VS2\": 4, \"SI1\": 3, \"SI2\": 2, \"I1\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Model: {model.__class__.__name__} | Accuracy: {score:.4f}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "xgb = XGBRegressor()\n",
    "lgbm = LGBMRegressor()\n",
    "\n",
    "evaluate_model(rf, X_train, X_val, y_train, y_val)\n",
    "evaluate_model(xgb, X_train, X_val, y_train, y_val)\n",
    "evaluate_model(lgbm, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"n_estimators\": [100, 200],\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    param_grid_xgb,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgbm = {\n",
    "    \"num_leaves\": [20, 31],\n",
    "    \"learning_rate\": [0.01, 0.05],\n",
    "    \"n_estimators\": [100, 300],\n",
    "}\n",
    "\n",
    "random_lgbm = RandomizedSearchCV(\n",
    "    LGBMClassifier(),\n",
    "    param_grid_lgbm,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LGBMClassifier(**random_lgbm.best_params_)\n",
    "final_model.fit(X_train, y_train)\n",
    "y_final_pred = final_model.predict(X_val)\n",
    "\n",
    "final_acc = accuracy_score(y_val, y_final_pred)\n",
    "print(f\"Final Model Accuracy: {final_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
